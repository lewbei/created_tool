{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "862989f4-ba3d-4fe2-a5e8-86373767e0d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing complete! Frames and annotations have been saved.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Load the annotations JSON file\n",
    "json_path = r'video1.json'\n",
    "with open(json_path, 'r') as f:\n",
    "    annotations = json.load(f)\n",
    "\n",
    "# Output directories for images and annotations\n",
    "output_img_dir = 'output_images'\n",
    "output_txt_dir = 'output_annotations'\n",
    "os.makedirs(output_img_dir, exist_ok=True)\n",
    "os.makedirs(output_txt_dir, exist_ok=True)\n",
    "\n",
    "# Define the FPS of the video and Label Studio\n",
    "video_fps = 59.19  # Actual video FPS\n",
    "label_studio_fps = 25.04  # Label Studio FPS\n",
    "scaling_factor = video_fps / label_studio_fps  # Scaling factor\n",
    "\n",
    "# Define a mapping from label names to class IDs\n",
    "label_to_class_id = {\n",
    "    \"1 star\": 0, \"2 stars\": 1, \"3 stars\": 2, \"4 stars\": 3, \"5 stars\": 4, \"6 stars\": 5,\n",
    "    \"7 stars\": 6, \"8 stars\": 7, \"Location\": 8, \"big monster\": 9, \"monster\": 10,\n",
    "    \"monster hp\": 11, \"monster name\": 12, \"player\": 13, \"player hp\": 14, \"player name\": 15,\n",
    "    \"quest\": 16, \"small monster\": 17, \"time\": 18, \"ultimate not ready\": 19, \"ultimate ready\": 20\n",
    "}\n",
    "\n",
    "# Function to check if a bounding box should be drawn in the current frame\n",
    "def get_boxes_for_frame(sequence, frame_number):\n",
    "    for i in range(len(sequence) - 1):\n",
    "        start_box = sequence[i]\n",
    "        end_box = sequence[i + 1]\n",
    "\n",
    "        # Scale Label Studio frames to match video FPS\n",
    "        start_frame = int(start_box['frame'] * scaling_factor)\n",
    "        end_frame = int(end_box['frame'] * scaling_factor)\n",
    "        \n",
    "        # Check if the current frame falls between the start_frame and end_frame\n",
    "        if start_frame <= frame_number < end_frame:\n",
    "            if start_box['enabled']:\n",
    "                return {\n",
    "                    'x': start_box['x'],\n",
    "                    'y': start_box['y'],\n",
    "                    'width': start_box['width'],\n",
    "                    'height': start_box['height'],\n",
    "                    'labels': start_box.get('labels', [])\n",
    "                }\n",
    "    return None\n",
    "\n",
    "# Function to write YOLO format annotations to a text file\n",
    "def write_yolo_annotations(txt_file_path, boxes, frame_width, frame_height):\n",
    "    with open(txt_file_path, 'w') as f:\n",
    "        for box in boxes:\n",
    "            if box:\n",
    "                # Get normalized YOLO format values\n",
    "                x_center = (box['x'] + box['width'] / 2) / 100  # x_center in percent\n",
    "                y_center = (box['y'] + box['height'] / 2) / 100  # y_center in percent\n",
    "                width = box['width'] / 100  # width in percent\n",
    "                height = box['height'] / 100  # height in percent\n",
    "\n",
    "                # Get the class ID for the label\n",
    "                if 'labels' in box and box['labels']:\n",
    "                    class_id = label_to_class_id.get(box['labels'][0], 0)\n",
    "                else:\n",
    "                    class_id = 0  # Default to 0 if no label found\n",
    "\n",
    "                # Write to the annotation file in YOLO format\n",
    "                f.write(f\"{class_id} {x_center} {y_center} {width} {height}\\n\")\n",
    "\n",
    "# Process each video in the annotations\n",
    "for annotation in annotations:\n",
    "    video_path = annotation['video']  # Update this to your local path if needed\n",
    "    video_filename = os.path.basename(video_path)\n",
    "\n",
    "    # Load video\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    # Get video properties\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)  # Frames per second\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    # Process frame by frame\n",
    "    frame_number = 0\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Collect all boxes for this frame from all classes\n",
    "        frame_boxes = []\n",
    "        for box_annotation in annotation['box']:\n",
    "            sequence = box_annotation['sequence']\n",
    "            box_for_frame = get_boxes_for_frame(sequence, frame_number)\n",
    "            if box_for_frame:\n",
    "                # Attach labels from the box annotation\n",
    "                box_for_frame['labels'] = box_annotation.get('labels', [])\n",
    "                frame_boxes.append(box_for_frame)\n",
    "\n",
    "        # Save frame as image\n",
    "        image_filename = f\"frame_{frame_number}.jpg\"\n",
    "        image_path = os.path.join(output_img_dir, image_filename)\n",
    "        cv2.imwrite(image_path, frame)\n",
    "\n",
    "        # Write the annotations for the current frame\n",
    "        txt_filename = f\"frame_{frame_number}.txt\"\n",
    "        txt_path = os.path.join(output_txt_dir, txt_filename)\n",
    "        write_yolo_annotations(txt_path, frame_boxes, width, height)\n",
    "\n",
    "        frame_number += 1\n",
    "        if frame_number >= total_frames:\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "print(\"Processing complete! Frames and annotations have been saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dad71f34-8702-4de6-8963-c38b46194357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original FPS of the video: 59.18777292576419\n",
      "Total number of frames in the video: 1506\n",
      "Total number of frames at 25.07 FPS: 637\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# Function to get the FPS and total frames of the video\n",
    "def get_video_info(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Cannot open video file\")\n",
    "        return None, None\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)  # Get frames per second\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))  # Get total number of frames\n",
    "    cap.release()\n",
    "    return fps, total_frames\n",
    "\n",
    "# Function to calculate the limited number of frames based on a target FPS\n",
    "def calculate_limited_frames(original_fps, total_frames, target_fps):\n",
    "    if target_fps > original_fps:\n",
    "        print(\"Target FPS is higher than the original FPS, no need to limit.\")\n",
    "        return total_frames\n",
    "    limited_frames = int((target_fps / original_fps) * total_frames)\n",
    "    return limited_frames\n",
    "\n",
    "# Example usage\n",
    "video_path = r'C:\\Users\\lewka\\deep learning\\MonsterHNow\\video\\video_from\\dd36f5e0-8.mp4'  # Replace with your actual video file path\n",
    "target_fps = 25.07  # Set your desired FPS\n",
    "\n",
    "# Get the original video information\n",
    "fps, total_frames = get_video_info(video_path)\n",
    "if fps is not None and total_frames is not None:\n",
    "    print(f\"Original FPS of the video: {fps}\")\n",
    "    print(f\"Total number of frames in the video: {total_frames}\")\n",
    "\n",
    "    # Calculate the limited number of frames\n",
    "    limited_frames = calculate_limited_frames(fps, total_frames, target_fps)\n",
    "    print(f\"Total number of frames at {target_fps} FPS: {limited_frames}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1c286acf-6836-4856-ad89-3dd25ac7e57f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recreated video saved at recreated_video.mp4\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "# Directories containing the extracted images and YOLO annotations\n",
    "image_dir = 'output_images'\n",
    "annotation_dir = 'output_annotations'\n",
    "\n",
    "# Define the output video path\n",
    "output_video_path = 'recreated_video.mp4'\n",
    "\n",
    "# Get sorted list of images by frame number to ensure sequential order\n",
    "image_list = sorted(os.listdir(image_dir), key=lambda x: int(os.path.splitext(x)[0].split('_')[1]))\n",
    "\n",
    "# Check if the directory is not empty\n",
    "if not image_list:\n",
    "    raise Exception(\"No images found in the directory\")\n",
    "\n",
    "# Load the first image to get video properties (width, height)\n",
    "first_image = cv2.imread(os.path.join(image_dir, image_list[0]))\n",
    "height, width, _ = first_image.shape\n",
    "\n",
    "# Create VideoWriter to save the recreated video\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(output_video_path, fourcc, 25, (width, height))  # 25 FPS is a placeholder, it won't impact the sequence\n",
    "\n",
    "# Function to load YOLO annotations from a text file\n",
    "def load_yolo_annotations(txt_file_path):\n",
    "    boxes = []\n",
    "    with open(txt_file_path, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            box_data = line.strip().split()\n",
    "            class_id = int(box_data[0])\n",
    "            x_center = float(box_data[1])\n",
    "            y_center = float(box_data[2])\n",
    "            width = float(box_data[3])\n",
    "            height = float(box_data[4])\n",
    "\n",
    "            boxes.append((class_id, x_center, y_center, width, height))\n",
    "    return boxes\n",
    "\n",
    "# Function to draw bounding boxes on a frame based on YOLO annotations\n",
    "def draw_yolo_boxes(frame, boxes, frame_width, frame_height):\n",
    "    for box in boxes:\n",
    "        class_id, x_center, y_center, width, height = box\n",
    "        \n",
    "        # Convert YOLO format (normalized) back to pixel values\n",
    "        x_center_px = int(x_center * frame_width)\n",
    "        y_center_px = int(y_center * frame_height)\n",
    "        box_width_px = int(width * frame_width)\n",
    "        box_height_px = int(height * frame_height)\n",
    "        \n",
    "        # Calculate the top-left corner of the bounding box\n",
    "        x_min = x_center_px - box_width_px // 2\n",
    "        y_min = y_center_px - box_height_px // 2\n",
    "        \n",
    "        # Draw rectangle around the object\n",
    "        cv2.rectangle(frame, (x_min, y_min), (x_min + box_width_px, y_min + box_height_px), (0, 255, 0), 2)\n",
    "        \n",
    "        # Draw the class ID on top of the box\n",
    "        label = f\"Class: {class_id}\"\n",
    "        cv2.putText(frame, label, (x_min, y_min - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "    return frame\n",
    "\n",
    "# Process each frame and corresponding annotation file\n",
    "for image_file in image_list:\n",
    "    # Load the image\n",
    "    image_path = os.path.join(image_dir, image_file)\n",
    "    frame = cv2.imread(image_path)\n",
    "\n",
    "    # Get the corresponding annotation file (.txt) based on the image filename\n",
    "    frame_number = os.path.splitext(image_file)[0]  # Extract \"frame_x\" from the filename\n",
    "    annotation_file = f\"{frame_number}.txt\"\n",
    "    annotation_path = os.path.join(annotation_dir, annotation_file)\n",
    "\n",
    "    # If the annotation file exists, load the bounding boxes\n",
    "    if os.path.exists(annotation_path):\n",
    "        boxes = load_yolo_annotations(annotation_path)\n",
    "        # Draw the bounding boxes on the frame\n",
    "        frame = draw_yolo_boxes(frame, boxes, width, height)\n",
    "\n",
    "    # Write the frame to the video\n",
    "    out.write(frame)\n",
    "\n",
    "# Release the VideoWriter\n",
    "out.release()\n",
    "\n",
    "print(f\"Recreated video saved at {output_video_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee5ebbb-d51c-4434-8b9f-4ee6f4f66b6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
