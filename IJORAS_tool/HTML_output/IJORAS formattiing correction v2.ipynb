{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2f0a00a-d05a-4aff-b1cb-9c73fbc9a165",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>[1]\tR. L. Siegel, K. D. Miller, N. S. Wagle, and A. Jemal, “Cancer Statistics, 2023,” <i>CA: A Cancer Journal for Clinicians</i>, vol. 73, no. 1, pp. 17–48, Jan. 2023.\n",
       "\tDOI: https://doi.org/10.3322/caac.21763.</pre>\n",
       "<pre>[2]\tK. V. Sriram and R. H. Havaldar, “Analytical Review And Study On Object Detection Techniques In The Image,” <i>International Journal of Modeling, Simulation, and Scientific Computing</i>, vol. 12, no. 05, pp. 2150031, Oct. 2021.\n",
       "\tDOI: https://doi.org/10.1142/S1793962321500318.</pre>\n",
       "<pre>[3]\tL. Fan, H. Zhao, H. Zhao, H. Hu, and Z. Wang, “Survey Of Target Detection Based On Deep Convolutional Neural Networks,” <i>Optics and Precision Engineering</i>, vol. 28, no. 5, pp. 1152–1164, 2020.\n",
       "\tDOI: https://doi.org/10.3788/ope.20202805.1152.</pre>\n",
       "<pre>[4]\tP. Viola and M. Jones, “Robust Real-Time Face Detection,”  pp. 747–747.\n",
       "\tDOI: https://doi.org/10.1109/ICCV.2001.937709.</pre>\n",
       "<pre>[5]\tN. Dalal and B. Triggs, “Histograms Of Oriented Gradients For Human Detection,”  pp. 886–893.\n",
       "\tDOI: https://doi.org/10.1109/CVPR.2005.177.</pre>\n",
       "<pre>[6]\tM. Hussain, “Yolo-V1 To Yolo-V8, The Rise Of Yolo And Its Complementary Nature Toward Digital Manufacturing And Industrial Defect Detection,” <i>Machines</i>, vol. 11, no. 7, pp. 677, Jun. 2023.\n",
       "\tDOI: https://doi.org/10.3390/machines11070677.</pre>\n",
       "<pre>[7]\tG. Sharma, R. Dave, J. Sanadya, P. Sharma, and K. K. Sharma, “Various Types And Management Of Breast Cancer: An Overview,” <i>Journal of Advanced Pharmaceutical Technology & Research</i>, vol. 1, no. 2, pp. 109, 2010.\n",
       "\tDOI: https://doi.org/10.4103/2231-4040.72251.</pre>\n",
       "<pre>[8]\tC. Li et al., “Yolov6: A Single-Stage Object Detection Framework For Industrial Applications,”  pp. 07, 2022.\n",
       "\tDOI: https://doi.org/10.48550/arXiv.2209.02976.</pre>\n",
       "<pre>[9]\tS. Zahia, D. Sierra-Sosa, B. Garcia-Zapirain, and A. Elmaghraby, “Tissue Classification And Segmentation Of Pressure Injuries Using Convolutional Neural Networks,”  pp. 51–58, Jun. 2018.\n",
       "\tDOI: https://doi.org/10.1016/j.cmpb.2018.02.018.</pre>\n",
       "<pre>[10]\tX. Sun, X. Wang, J. Liu, and H. Huang, “Classic Yolo Series Target Detection Algorithms And Their Application In Breast Cancer Detection,” <i>J. Comput. Syst. Appl.</i>, vol. 32, no. 12, pp. 52–62, 2023.\n",
       "\tDOI: https://doi.org/10.15888/j.cnki.csa.009351.</pre>\n",
       "<pre>[11]\tF. Prinzi, M. Insalaco, A. Orlando, S. Gaglio, and S. Vitabile, “A Yolo-Based Model For Breast Cancer Detection In Mammograms,” <i>Cogn. Comput.</i>, vol. 16, no. 1, pp. 107–120, Jan. 2024.\n",
       "\tDOI: https://doi.org/10.1007/s12559-023-10189-6.</pre>\n",
       "<pre>[12]\tP. K. Samanta, A. Basuli, N. K. Rout, and G. Panda, “Improved Breast Cancer Detection From Ultrasound Images Using Yolov8 Model,”  pp. 1–6.\n",
       "\tDOI: https://doi.org/10.1109/AESPC59761.2023.10390341.</pre>\n",
       "<pre>[13]\tH. Gui et al., “Fs-Yolov9: A Frequency And Spatial Feature-Based Yolov9 For Real-Time Breast Cancer Detection,”  \n",
       "\tDOI: https://doi.org/10.1016/j.acra.2024.09.048.</pre>\n",
       "<pre>[14]\tL. Zheng et al., “Judging Llm-As-A-Judge With Mt-Bench And Chatbot Arena,”  \n",
       "\tDOI: https://doi.org/10.48550/arXiv.2306.05685.</pre>\n",
       "<pre>[15]\tA. Y. Yuan et al., “Hybrid Deep Learning Network For Vascular Segmentation In Photoacoustic Imaging,” <i>Biomedical Optics Express</i>, vol. 11, no. 11, pp. 6445, Nov. 2020.\n",
       "\tDOI: https://doi.org/10.1364/BOE.409246.</pre>\n",
       "<pre>[16]\tW. Al-Dhabyani, M. Gomaa, H. Khaled, and A. Fahmy, “Dataset Of Breast Ultrasound Images,”  pp. 104863, Feb. 2020.\n",
       "\tDOI: https://doi.org/10.1016/j.dib.2019.104863.</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from IPython.display import HTML\n",
    "\n",
    "def load_journal_full_names(filename=\"journals.json\"):\n",
    "    \"\"\"Load and normalize journal full names from a JSON file.\n",
    "       Return a dictionary mapping normalized keys to the full names (plain text).\"\"\"\n",
    "    try:\n",
    "        with open(filename, \"r\", encoding=\"utf-8\") as file:\n",
    "            data = json.load(file)\n",
    "            # Return full names as plain text.\n",
    "            return {key.lower().replace(\".\", \"\").replace(\",\", \"\"): value for key, value in data.items()}\n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: journals.json not found!\")\n",
    "        return {}\n",
    "\n",
    "def normalize_journal_name(journal_name):\n",
    "    \"\"\"Normalize journal name (remove dots, lowercase) for comparison.\"\"\"\n",
    "    return journal_name.lower().replace(\".\", \"\").replace(\",\", \"\")\n",
    "\n",
    "def classify_reference(reference):\n",
    "    \"\"\"Classify references into categories (Journal, Conference, arXiv, Dataset, Other).\"\"\"\n",
    "    if \"arXiv\" in reference:\n",
    "        return \"arXiv\"\n",
    "    elif \"Proceedings\" in reference or \"Conference\" in reference or \"in \" in reference:\n",
    "        return \"Conference\"\n",
    "    elif re.search(r\"vol\\.\\s*\\d+\", reference):\n",
    "        return \"Journal\"\n",
    "    elif \"Dataset\" in reference:\n",
    "        return \"Dataset\"\n",
    "    else:\n",
    "        return \"Other\"\n",
    "\n",
    "def extract_year(reference):\n",
    "    \"\"\"Extract the year from a reference.\"\"\"\n",
    "    match = re.search(r'\\b(19|20)\\d{2}\\b', reference)\n",
    "    return match.group(0) if match else \"Unknown\"\n",
    "\n",
    "def extract_journal_name(reference, journal_full_names, missing_journals, ref_index):\n",
    "    \"\"\"Extract journal name and replace it with its full name (plain text) if found.\"\"\"\n",
    "    match = re.search(r'“.*?”\\s*(.*?)\\s*,\\s*vol\\.', reference)\n",
    "    if match:\n",
    "        abbr_name = match.group(1).strip()\n",
    "        normalized_name = normalize_journal_name(abbr_name)\n",
    "        if normalized_name in journal_full_names:\n",
    "            return journal_full_names[normalized_name]\n",
    "        else:\n",
    "            missing_journals[abbr_name].append(f\"[{ref_index}]\")\n",
    "            return abbr_name\n",
    "    elif re.search(r'“.*?”\\s*([A-Za-z\\s]+),', reference):\n",
    "        abbr_name = re.search(r'“.*?”\\s*([A-Za-z\\s]+),', reference).group(1).strip()\n",
    "        normalized_name = normalize_journal_name(abbr_name)\n",
    "        if normalized_name in journal_full_names:\n",
    "            return journal_full_names[normalized_name]\n",
    "        else:\n",
    "            missing_journals[abbr_name].append(f\"[{ref_index}]\")\n",
    "            return abbr_name\n",
    "    else:\n",
    "        return \"Unknown Journal\"\n",
    "\n",
    "def check_format_issues(reference):\n",
    "    \"\"\"\n",
    "    Check for missing components in the reference.\n",
    "    In particular, verify:\n",
    "      - The volume number exists.\n",
    "      - The issue number exists.\n",
    "      - The page numbers exist and contain a dash (\"-\" or \"–\").\n",
    "    Returns a tuple: (list_of_issue_messages, details_string)\n",
    "    \"\"\"\n",
    "    issues = []\n",
    "    \n",
    "    # Check volume\n",
    "    vol_match = re.search(r\"vol\\.\\s*(\\d+)\", reference)\n",
    "    if not vol_match:\n",
    "        issues.append(\"Missing Volume\")\n",
    "    \n",
    "    # Check issue\n",
    "    no_match = re.search(r\"no\\.\\s*(\\d+)\", reference)\n",
    "    if not no_match:\n",
    "        issues.append(\"Missing Issue Number\")\n",
    "    \n",
    "    # Check pages (allow both \"p.\" and \"pp.\")\n",
    "    pages_match = re.search(r\"p{1,2}\\.\\s*([\\d–-]+)\", reference)\n",
    "    if pages_match:\n",
    "        pages_value = pages_match.group(1)\n",
    "        # Check if the page string contains a dash\n",
    "        if (\"-\" not in pages_value) and (\"–\" not in pages_value):\n",
    "            issues.append(\"Incorrect or Missing Page Numbers\")\n",
    "    else:\n",
    "        issues.append(\"Incorrect or Missing Page Numbers\")\n",
    "    \n",
    "    # Build details string only if there are issues\n",
    "    details_parts = []\n",
    "    if \"Missing Volume\" in issues:\n",
    "        details_parts.append(\"vol: missing\")\n",
    "    if \"Missing Issue Number\" in issues:\n",
    "        details_parts.append(\"no: missing\")\n",
    "    if \"Incorrect or Missing Page Numbers\" in issues:\n",
    "        details_parts.append(\"pp: Missing\")\n",
    "    \n",
    "    details_string = \"\"\n",
    "    if details_parts:\n",
    "        details_string = \" (\" + \", \".join(details_parts) + \")\"\n",
    "    \n",
    "    return issues, details_string\n",
    "\n",
    "def report_reference_fields(reference, ref_index):\n",
    "    \"\"\"\n",
    "    Extract and return a detailed report of the fields in a reference.\n",
    "    The report includes:\n",
    "      - Authors\n",
    "      - Title\n",
    "      - Journal name\n",
    "      - Volume\n",
    "      - Issue\n",
    "      - Page numbers (set to Missing if a dash is not found)\n",
    "      - Year\n",
    "      - DOI\n",
    "    \"\"\"\n",
    "    report = []\n",
    "    # Authors:\n",
    "    author_match = re.search(r\"^\\[\\d+\\]\\s*(.*?),\\s*“\", reference)\n",
    "    authors = author_match.group(1) if author_match else \"Missing\"\n",
    "    report.append(f\"Authors: {authors}\")\n",
    "    \n",
    "    # Title:\n",
    "    title_match = re.search(r\"“(.*?)”\", reference)\n",
    "    title = title_match.group(1) if title_match else \"Missing\"\n",
    "    report.append(f\"Title: {title}\")\n",
    "    \n",
    "    # Journal:\n",
    "    journal_match = re.search(r'“.*?”\\s*(.*?)\\s*,\\s*vol\\.', reference)\n",
    "    journal = journal_match.group(1) if journal_match else \"Missing\"\n",
    "    report.append(f\"Journal: {journal}\")\n",
    "    \n",
    "    # Volume:\n",
    "    vol_match = re.search(r\"vol\\.\\s*(\\d+)\", reference)\n",
    "    volume = vol_match.group(1) if vol_match else \"Missing\"\n",
    "    report.append(f\"Volume: {volume}\")\n",
    "    \n",
    "    # Issue:\n",
    "    issue_match = re.search(r\"no\\.\\s*(\\d+)\", reference)\n",
    "    issue = issue_match.group(1) if issue_match else \"Missing\"\n",
    "    report.append(f\"Issue: {issue}\")\n",
    "    \n",
    "    # Page Numbers:\n",
    "    pages_match = re.search(r\"p{1,2}\\.\\s*([\\d–-]+)\", reference)\n",
    "    if pages_match:\n",
    "        pages = pages_match.group(1)\n",
    "        if (\"-\" not in pages) and (\"–\" not in pages):\n",
    "            pages = \"Missing\"\n",
    "    else:\n",
    "        pages = \"Missing\"\n",
    "    report.append(f\"Page numbers: {pages}\")\n",
    "    \n",
    "    # Year:\n",
    "    year = extract_year(reference)\n",
    "    report.append(f\"Year: {year}\")\n",
    "    \n",
    "    # DOI:\n",
    "    doi_match = re.search(r\"doi:\\s*(\\S+)\", reference)\n",
    "    doi = doi_match.group(1) if doi_match else \"Missing\"\n",
    "    report.append(f\"DOI: {doi}\")\n",
    "    \n",
    "    return \"\\n\".join(report)\n",
    "\n",
    "def format_reference_html(index, reference, journal_full_names, missing_journals):\n",
    "    \"\"\"\n",
    "    Generate an HTML-formatted reference.\n",
    "    This replicates your plain-text formatting and wraps the journal name in <i> tags.\n",
    "    The entire reference is enclosed in a <pre> tag to preserve alignment.\n",
    "    \"\"\"\n",
    "    author_pattern = r\"^\\[\\d+\\]\\s*(.*?),\\s*“\"\n",
    "    title_pattern  = r\"“(.*?)”\"\n",
    "    journal_pattern = r\"([A-Za-z\\s\\.\\-]+),\\s*vol\\.\\s*(\\S+),\\s*no\\.\\s*(\\d+),?\"\n",
    "    pages_pattern   = r\"p{1,2}\\.\\s*([\\d–-]+)(?:,\\s*([^,]+))?,\"\n",
    "    doi_pattern     = r\"doi:\\s*(\\S+)\"\n",
    "    \n",
    "    authors = re.search(author_pattern, reference)\n",
    "    title   = re.search(title_pattern, reference)\n",
    "    journal = re.search(journal_pattern, reference)\n",
    "    pages   = re.search(pages_pattern, reference)\n",
    "    doi     = re.search(doi_pattern, reference)\n",
    "    \n",
    "    formatted_authors = authors.group(1) if authors else \"\"\n",
    "    formatted_title   = f\"“{title.group(1).title()}”\" if title else \"\"\n",
    "    \n",
    "    if journal:\n",
    "        journal_name = extract_journal_name(reference, journal_full_names, missing_journals, index)\n",
    "        # Wrap journal name in <i> tags for italics.\n",
    "        formatted_journal = f\"<i>{journal_name}</i>, vol. {journal.group(2)}, no. {journal.group(3)},\"\n",
    "    else:\n",
    "        formatted_journal = \"\"\n",
    "    \n",
    "    if pages:\n",
    "        pages_text = pages.group(1)\n",
    "        extra_text = pages.group(2) if pages.lastindex and pages.group(2) else \"\"\n",
    "        if extra_text:\n",
    "            formatted_pages = f\"pp. {pages_text}, {extra_text}.\"\n",
    "        else:\n",
    "            formatted_pages = f\"pp. {pages_text}.\"\n",
    "    else:\n",
    "        formatted_pages = \"\"\n",
    "    \n",
    "    # DOI printed as plain text.\n",
    "    formatted_doi = f\"\\n\\tDOI: https://doi.org/{doi.group(1)}\" if doi else \"\"\n",
    "    \n",
    "    # Enclose the entire formatted reference in a <pre> tag to preserve alignment.\n",
    "    html_ref = f\"<pre>[{index}]\\t{formatted_authors}, {formatted_title} {formatted_journal} {formatted_pages}{formatted_doi}</pre>\"\n",
    "    return html_ref\n",
    "\n",
    "def process_references_html(input_text, start_index=1):\n",
    "    \"\"\"\n",
    "    Process the input references and generate a single HTML string\n",
    "    containing all formatted references.\n",
    "    \"\"\"\n",
    "    journal_full_names = load_journal_full_names()\n",
    "    missing_journals = defaultdict(list)\n",
    "    references = re.split(r'\\n(?=\\[\\d+\\])', input_text.strip())\n",
    "    html_references = []\n",
    "    \n",
    "    for i, ref in enumerate(references):\n",
    "        html_ref = format_reference_html(start_index + i, ref, journal_full_names, missing_journals)\n",
    "        html_references.append(html_ref)\n",
    "    \n",
    "    return \"\\n\".join(html_references)\n",
    "\n",
    "def process_references_summary(input_text, start_index=1):\n",
    "    \"\"\"\n",
    "    Process references using the original logic to extract summary statistics,\n",
    "    formatted references (plain-text), and detailed issues.\n",
    "    Returns a tuple (formatted_references, detailed_issues, summary_stats).\n",
    "    \"\"\"\n",
    "    journal_full_names = load_journal_full_names()\n",
    "    missing_journals = defaultdict(list)\n",
    "    references = re.split(r'\\n(?=\\[\\d+\\])', input_text.strip())\n",
    "    formatted_references = []\n",
    "    detailed_issues = []\n",
    "    ref_type_counts = {\"Journal\": [], \"Conference\": [], \"arXiv\": [], \"Other\": []}\n",
    "    jca_years = defaultdict(list)\n",
    "    overall_years = defaultdict(list)\n",
    "\n",
    "    for i, ref in enumerate(references):\n",
    "        # Extract fields (similar to your original plain-text formatting)\n",
    "        author_pattern = r\"^\\[\\d+\\]\\s*(.*?),\\s*“\"\n",
    "        title_pattern  = r\"“(.*?)”\"\n",
    "        journal_pattern = r\"([A-Za-z\\s\\.\\-]+),\\s*vol\\.\\s*(\\S+),\\s*no\\.\\s*(\\d+),?\"\n",
    "        pages_pattern   = r\"p{1,2}\\.\\s*([\\d–-]+)(?:,\\s*([^,]+))?,\"\n",
    "        doi_pattern     = r\"doi:\\s*(\\S+)\"\n",
    "        \n",
    "        authors = re.search(author_pattern, ref)\n",
    "        title   = re.search(title_pattern, ref)\n",
    "        journal = re.search(journal_pattern, ref)\n",
    "        pages   = re.search(pages_pattern, ref)\n",
    "        doi     = re.search(doi_pattern, ref)\n",
    "        \n",
    "        formatted_authors = authors.group(1) if authors else \"\"\n",
    "        formatted_title   = f\"“{title.group(1).title()}”\" if title else \"\"\n",
    "        if journal:\n",
    "            journal_name = extract_journal_name(ref, journal_full_names, missing_journals, i+start_index)\n",
    "            formatted_journal = f\"{journal_name}, vol. {journal.group(2)}, no. {journal.group(3)},\"\n",
    "        else:\n",
    "            formatted_journal = \"\"\n",
    "        if pages:\n",
    "            pages_text = pages.group(1)\n",
    "            extra_text = pages.group(2) if pages.lastindex and pages.group(2) else \"\"\n",
    "            if extra_text:\n",
    "                formatted_pages = f\"pp. {pages_text}, {extra_text}.\"\n",
    "            else:\n",
    "                formatted_pages = f\"pp. {pages_text}.\"\n",
    "        else:\n",
    "            formatted_pages = \"\"\n",
    "        formatted_doi = f\"\\n\\tDOI: https://doi.org/{doi.group(1)}\" if doi else \"\"\n",
    "        formatted_ref = f\"[{i+start_index}]\\t{formatted_authors}, {formatted_title} {formatted_journal} {formatted_pages}{formatted_doi}\"\n",
    "        formatted_references.append(formatted_ref)\n",
    "        \n",
    "        # Process issues.\n",
    "        issues, details_string = check_format_issues(ref)\n",
    "        if issues:\n",
    "            issues_str = \", \".join(issues) + details_string\n",
    "        else:\n",
    "            issues_str = \"None\"\n",
    "        detailed_issues.append(f\"Reference [{i+start_index}] {extract_year(ref)} Issues: {issues_str}\")\n",
    "        \n",
    "        # Update reference type counts and years.\n",
    "        ref_type = classify_reference(ref)\n",
    "        year = extract_year(ref)\n",
    "        ref_type_counts[ref_type].append((i+start_index, year))\n",
    "        overall_years[year].append(i+start_index)\n",
    "        if ref_type in (\"Journal\", \"Conference\", \"arXiv\"):\n",
    "            jca_years[year].append(i+start_index)\n",
    "    \n",
    "    summary_stats = {\n",
    "        \"ref_type_counts\": ref_type_counts,\n",
    "        \"jca_years\": dict(jca_years),\n",
    "        \"overall_years\": dict(overall_years),\n",
    "        \"missing_journals\": dict(missing_journals)\n",
    "    }\n",
    "    \n",
    "    return \"\\n\".join(formatted_references), detailed_issues, summary_stats\n",
    "\n",
    "def generate_summary_html(summary_stats):\n",
    "    \"\"\"\n",
    "    Generate HTML output for summary statistics:\n",
    "      - Reference Type Counts\n",
    "      - Paper Year (Journal/Conference/arXiv)\n",
    "      - Paper Year (Total)\n",
    "      - Journals Not Found in JSON (Check Manually)\n",
    "    \"\"\"\n",
    "    summary_html = \"<h3>Reference Type Counts:</h3><pre>\"\n",
    "    for ref_type, entries in summary_stats[\"ref_type_counts\"].items():\n",
    "        entries_str = \" \".join([f\"[{idx}] {yr}\" for idx, yr in entries])\n",
    "        summary_html += f\"{ref_type}: {len(entries)}\\n{entries_str}\\n\"\n",
    "    summary_html += \"</pre>\"\n",
    "    \n",
    "    summary_html += \"<h3>Paper Year (Journal/Conference/arXiv):</h3><pre>\"\n",
    "    for year in sorted(summary_stats[\"jca_years\"].keys(), key=lambda x: int(x), reverse=True):\n",
    "        refs = sorted(summary_stats[\"jca_years\"][year])\n",
    "        refs_str = \", \".join([f\"[{idx}]\" for idx in refs])\n",
    "        summary_html += f\"{year}: {len(refs)} ({refs_str})\\n\"\n",
    "    summary_html += \"</pre>\"\n",
    "    \n",
    "    summary_html += \"<h3>Paper Year (Total):</h3><pre>\"\n",
    "    for year in sorted(summary_stats[\"overall_years\"].keys(), key=lambda x: int(x), reverse=True):\n",
    "        refs = sorted(summary_stats[\"overall_years\"][year])\n",
    "        refs_str = \", \".join([f\"[{idx}]\" for idx in refs])\n",
    "        summary_html += f\"{year}: {len(refs)} ({refs_str})\\n\"\n",
    "    summary_html += \"</pre>\"\n",
    "    \n",
    "    summary_html += \"<h3>Journals Not Found in JSON (Check Manually):</h3><pre>\"\n",
    "    if summary_stats[\"missing_journals\"]:\n",
    "        for journal, ref_list in summary_stats[\"missing_journals\"].items():\n",
    "            ref_str = \" \".join(ref_list)\n",
    "            summary_html += f\"{journal}: {ref_str}\\n\"\n",
    "    else:\n",
    "        summary_html += \"None\\n\"\n",
    "    summary_html += \"</pre>\"\n",
    "    \n",
    "    return summary_html\n",
    "\n",
    "def generate_detailed_issues_html(detailed_issues):\n",
    "    \"\"\"Generate HTML output for the 'Format Issues Detected' section.\"\"\"\n",
    "    html = \"<h3>Format Issues Detected:</h3><pre>\"\n",
    "    for issue in detailed_issues:\n",
    "        html += issue + \"\\n\"\n",
    "    html += \"</pre>\"\n",
    "    return html\n",
    "\n",
    "def generate_detailed_report_html(input_text):\n",
    "    \"\"\"\n",
    "    Generate HTML output for the 'Detailed Report per Reference' section.\n",
    "    Uses the report_reference_fields function for each reference.\n",
    "    \"\"\"\n",
    "    references = re.split(r'\\n(?=\\[\\d+\\])', input_text.strip())\n",
    "    html = \"<h3>Detailed Report per Reference:</h3>\"\n",
    "    for i, ref in enumerate(references, start=1):\n",
    "        report = report_reference_fields(ref, i)\n",
    "        html += f\"<h4>Reference [{i}] Fields:</h4><pre>{report}</pre>\"\n",
    "    return html\n",
    "\n",
    "# --- Example Usage in Jupyter Notebook ---\n",
    "\n",
    "input_references = \"\"\"[1]\tR. L. Siegel, K. D. Miller, N. S. Wagle, and A. Jemal, “Cancer statistics, 2023,” CA. Cancer J. Clin., vol. 73, no. 1, pp. 17–48, Jan. 2023, doi: 10.3322/caac.21763.\n",
    "[2]\tK. V. Sriram and R. H. Havaldar, “Analytical review and study on object detection techniques in the image,” Int. J. Model. Simul. Sci. Comput., vol. 12, no. 05, p. 2150031, Oct. 2021, doi: 10.1142/S1793962321500318.\n",
    "[3]\tL. Fan, H. Zhao, H. Zhao, H. Hu, and Z. Wang, “Survey of target detection based on deep convolutional neural networks,” Opt. Precis. Eng., vol. 28, no. 5, pp. 1152–1164, 2020, doi: 10.3788/ope.20202805.1152.\n",
    "[4]\tP. Viola and M. Jones, “Robust real-time face detection,” in Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001, Vancouver, BC, Canada: IEEE Comput. Soc, 2001, pp. 747–747, doi: 10.1109/ICCV.2001.937709.\n",
    "[5]\tN. Dalal and B. Triggs, “Histograms of Oriented Gradients for Human Detection,” in 2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR’05), San Diego, CA, USA: IEEE, 2005, pp. 886–893, doi: 10.1109/CVPR.2005.177.\n",
    "[6]\tM. Hussain, “YOLO-v1 to YOLO-v8, the Rise of YOLO and Its Complementary Nature toward Digital Manufacturing and Industrial Defect Detection,” Machines, vol. 11, no. 7, p. 677, Jun. 2023, doi: 10.3390/machines11070677.\n",
    "[7]\tG. Sharma, R. Dave, J. Sanadya, P. Sharma, and K. K. Sharma, “Various types and management of breast cancer: An overview,” J. Adv. Pharm. Technol. Res., vol. 1, no. 2, p. 109, 2010, doi: 10.4103/2231-4040.72251.\n",
    "[8]\tC. Li et al., “YOLOv6: A Single-Stage Object Detection Framework for Industrial Applications,” Sep. 07, 2022, arXiv: arXiv:2209.02976, doi: 10.48550/arXiv.2209.02976.\n",
    "[9]\tS. Zahia, D. Sierra-Sosa, B. Garcia-Zapirain, and A. Elmaghraby, “Tissue classification and segmentation of pressure injuries using convolutional neural networks,” Comput. Methods Programs Biomed., vol. 159, pp. 51–58, Jun. 2018, doi: 10.1016/j.cmpb.2018.02.018.\n",
    "[10]\tX. Sun, X. Wang, J. Liu, and H. Huang, “Classic YOLO Series Target Detection Algorithms and Their Application in Breast Cancer Detection,” J. Comput. Syst. Appl., vol. 32, no. 12, pp. 52–62, 2023, doi: 10.15888/j.cnki.csa.009351.\n",
    "[11]\tF. Prinzi, M. Insalaco, A. Orlando, S. Gaglio, and S. Vitabile, “A Yolo-Based Model for Breast Cancer Detection in Mammograms,” Cogn. Comput., vol. 16, no. 1, pp. 107–120, Jan. 2024, doi: 10.1007/s12559-023-10189-6.\n",
    "[12]\tP. K. Samanta, A. Basuli, N. K. Rout, and G. Panda, “Improved Breast Cancer Detection from Ultrasound Images Using YOLOv8 Model,” in 2023 IEEE 3rd International Conference on Applied Electromagnetics, Signal Processing, & Communication (AESPC), Bhubaneswar, India: IEEE, Nov. 2023, pp. 1–6, doi: 10.1109/AESPC59761.2023.10390341.\n",
    "[13]\tH. Gui et al., “FS-YOLOv9: A Frequency and Spatial Feature-Based YOLOv9 for Real-time Breast Cancer Detection,” Acad. Radiol., Oct. 2024, doi: 10.1016/j.acra.2024.09.048.\n",
    "[14]\tL. Zheng et al., “Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena,” Dec. 24, 2023, arXiv: arXiv:2306.05685, doi: 10.48550/arXiv.2306.05685.\n",
    "[15]\tA. Y. Yuan et al., “Hybrid deep learning network for vascular segmentation in photoacoustic imaging,” Biomed. Opt. Express, vol. 11, no. 11, p. 6445, Nov. 2020, doi: 10.1364/BOE.409246.\n",
    "[16]\tW. Al-Dhabyani, M. Gomaa, H. Khaled, and A. Fahmy, “Dataset of breast ultrasound images,” Data Brief, vol. 28, p. 104863, Feb. 2020, doi: 10.1016/j.dib.2019.104863.\n",
    "\"\"\"\n",
    "\n",
    "# Generate HTML for the formatted references.\n",
    "html_references = process_references_html(input_references)\n",
    "\n",
    "# Process references (plain-text) to extract detailed issues and summary statistics.\n",
    "_, detailed_issues, summary_stats = process_references_summary(input_references)\n",
    "\n",
    "# Generate HTML for the summary statistics.\n",
    "summary_html = generate_summary_html(summary_stats)\n",
    "\n",
    "# Generate HTML for the Format Issues Detected.\n",
    "issues_html = generate_detailed_issues_html(detailed_issues)\n",
    "\n",
    "# Generate HTML for the Detailed Report per Reference.\n",
    "report_html = generate_detailed_report_html(input_references)\n",
    "\n",
    "# Combine all HTML outputs.\n",
    "final_html = (\n",
    "    html_references +\n",
    "    \"<br/><hr/><br/>\" +\n",
    "    issues_html +\n",
    "    \"<br/><hr/><br/>\" +\n",
    "    report_html +\n",
    "    \"<br/><hr/><br/>\" +\n",
    "    summary_html\n",
    ")\n",
    "\n",
    "# Render the final HTML output in Jupyter Notebook.\n",
    "HTML(final_html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebc895c-6646-4505-a818-0b4014211dd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
