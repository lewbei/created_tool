{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943d4d54-ecb7-47be-ae7c-cdca0e99b3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "def load_journal_full_names(filename=\"journals.json\"):\n",
    "    \"\"\"Load and normalize journal full names from a JSON file.\n",
    "       Return a dictionary mapping normalized keys to the full names (plain text).\"\"\"\n",
    "    try:\n",
    "        with open(filename, \"r\", encoding=\"utf-8\") as file:\n",
    "            data = json.load(file)\n",
    "            # Return full names as plain text.\n",
    "            return {key.lower().replace(\".\", \"\").replace(\",\", \"\"): value for key, value in data.items()}\n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: journals.json not found!\")\n",
    "        return {}\n",
    "\n",
    "def normalize_journal_name(journal_name):\n",
    "    \"\"\"Normalize journal name (remove dots, lowercase) for comparison.\"\"\"\n",
    "    return journal_name.lower().replace(\".\", \"\").replace(\",\", \"\")\n",
    "\n",
    "def classify_reference(reference):\n",
    "    \"\"\"Classify references into categories (Journal, Conference, arXiv, Dataset, Other).\"\"\"\n",
    "    if \"arXiv\" in reference:\n",
    "        return \"arXiv\"\n",
    "    elif \"Proceedings\" in reference or \"Conference\" in reference or \"in \" in reference:\n",
    "        return \"Conference\"\n",
    "    elif re.search(r\"vol\\.\\s*\\d+\", reference):\n",
    "        return \"Journal\"\n",
    "    elif \"Dataset\" in reference:\n",
    "        return \"Dataset\"\n",
    "    else:\n",
    "        return \"Other\"\n",
    "\n",
    "def extract_year(reference):\n",
    "    \"\"\"Extract the year from a reference.\"\"\"\n",
    "    match = re.search(r'\\b(19|20)\\d{2}\\b', reference)\n",
    "    return match.group(0) if match else \"Unknown\"\n",
    "\n",
    "def extract_journal_name(reference, journal_full_names, missing_journals, ref_index):\n",
    "    \"\"\"Extract journal name and replace it with its full name (plain text) if found.\"\"\"\n",
    "    match = re.search(r'“.*?”\\s*(.*?)\\s*,\\s*vol\\.', reference)\n",
    "    if match:\n",
    "        abbr_name = match.group(1).strip()\n",
    "        normalized_name = normalize_journal_name(abbr_name)\n",
    "        if normalized_name in journal_full_names:\n",
    "            return journal_full_names[normalized_name]\n",
    "        else:\n",
    "            missing_journals[abbr_name].append(f\"[{ref_index}]\")\n",
    "            return abbr_name\n",
    "    elif re.search(r'“.*?”\\s*([A-Za-z\\s]+),', reference):\n",
    "        abbr_name = re.search(r'“.*?”\\s*([A-Za-z\\s]+),', reference).group(1).strip()\n",
    "        normalized_name = normalize_journal_name(abbr_name)\n",
    "        if normalized_name in journal_full_names:\n",
    "            return journal_full_names[normalized_name]\n",
    "        else:\n",
    "            missing_journals[abbr_name].append(f\"[{ref_index}]\")\n",
    "            return abbr_name\n",
    "    else:\n",
    "        return \"Unknown Journal\"\n",
    "\n",
    "def check_format_issues(reference):\n",
    "    \"\"\"\n",
    "    Check for missing components in the reference.\n",
    "    Also, attempt to extract the page numbers portion.\n",
    "    Returns a tuple: (list_of_issue_messages, extracted_pages)\n",
    "    \"\"\"\n",
    "    issues = []\n",
    "    pages_match = re.search(r\"pp\\.\\s*([\\d–]+)\", reference)\n",
    "    extracted_pages = pages_match.group(1) if pages_match else \"Missing\"\n",
    "    \n",
    "    if not pages_match:\n",
    "        issues.append(\"Incorrect or Missing Page Numbers\")\n",
    "    if not re.search(r\"doi:\\s*10\\.\", reference):\n",
    "        issues.append(\"Invalid DOI format\")\n",
    "    if not re.search(r\"vol\\.\\s*\\d+\", reference):\n",
    "        issues.append(\"Missing Volume\")\n",
    "    if not re.search(r\"no\\.\\s*\\d+\", reference):\n",
    "        issues.append(\"Missing Issue Number\")\n",
    "    \n",
    "    return issues, extracted_pages\n",
    "\n",
    "def format_reference(index, reference, journal_full_names, missing_journals):\n",
    "    \"\"\"\n",
    "    Format a single reference.\n",
    "    The formatted reference is produced as in your original code.\n",
    "    Additionally, extract the list of format issues and the page numbers portion.\n",
    "    \"\"\"\n",
    "    author_pattern = r\"^\\[\\d+\\]\\s*(.*?),\\s*“\"\n",
    "    title_pattern  = r\"“(.*?)”\"\n",
    "    journal_pattern = r\"([A-Za-z\\s\\.\\-]+),\\s*vol\\.\\s*(\\S+),\\s*no\\.\\s*(\\d+),?\"\n",
    "    # Updated pages pattern: captures pages and, if present, extra text.\n",
    "    pages_pattern   = r\"pp?\\.\\s*([\\d–]+)(?:,\\s*([^,]+))?,\"\n",
    "    doi_pattern     = r\"doi:\\s*(\\S+)\"\n",
    "    \n",
    "    authors = re.search(author_pattern, reference)\n",
    "    title   = re.search(title_pattern, reference)\n",
    "    journal = re.search(journal_pattern, reference)\n",
    "    pages   = re.search(pages_pattern, reference)\n",
    "    doi     = re.search(doi_pattern, reference)\n",
    "    \n",
    "    formatted_authors = authors.group(1) if authors else \"\"\n",
    "    formatted_title   = f\"“{title.group(1).title()}”\" if title else \"\"\n",
    "    \n",
    "    if journal:\n",
    "        journal_name = extract_journal_name(reference, journal_full_names, missing_journals, index)\n",
    "        formatted_journal = f\"{journal_name}, vol. {journal.group(2)}, no. {journal.group(3)},\"\n",
    "    else:\n",
    "        formatted_journal = \"\"\n",
    "    \n",
    "    if pages:\n",
    "        pages_text = pages.group(1)\n",
    "        extra_text = pages.group(2) if pages.lastindex and pages.group(2) else \"\"\n",
    "        if extra_text:\n",
    "            formatted_pages = f\"pp. {pages_text}, {extra_text}.\"\n",
    "        else:\n",
    "            formatted_pages = f\"pp. {pages_text}.\"\n",
    "    else:\n",
    "        formatted_pages = \"\"\n",
    "    \n",
    "    # **DOI as a link but not a hyperlink:** Insert zero-width spaces between parts so that it shows as:\n",
    "    # \"https://doi.org/10.3322/caac.21763\" but is not automatically recognized as a hyperlink.\n",
    "    formatted_doi = f\"\\n\\tDOI: https:\\u200B//\\u200Bdoi.org/{doi.group(1)}\" if doi else \"\"\n",
    "    \n",
    "    formatted_ref = f\"[{index}]\\t{formatted_authors}, {formatted_title} {formatted_journal} {formatted_pages}{formatted_doi}\"\n",
    "    \n",
    "    ref_type = classify_reference(reference)\n",
    "    year = extract_year(reference)\n",
    "    issues, extracted_pages = check_format_issues(reference)\n",
    "    \n",
    "    return formatted_ref, ref_type, index, year, formatted_journal, issues, extracted_pages\n",
    "\n",
    "def process_references(input_text, start_index=1):\n",
    "    \"\"\"\n",
    "    Process and analyze references.\n",
    "    Returns a tuple of two values:\n",
    "      1. A string of all formatted references (one per line)\n",
    "      2. A list of detailed format issues per reference.\n",
    "    \"\"\"\n",
    "    journal_full_names = load_journal_full_names()\n",
    "    references = re.split(r'\\n(?=\\[\\d+\\])', input_text.strip())\n",
    "    formatted_references = []\n",
    "    detailed_issues = []  # List of strings: one per reference with issues report\n",
    "    \n",
    "    for i, ref in enumerate(references):\n",
    "        formatted_ref, _, ref_index, year, _, issues, extracted_pages = format_reference(\n",
    "            start_index + i, ref, journal_full_names, defaultdict(list))\n",
    "        formatted_references.append(formatted_ref)\n",
    "        if issues:\n",
    "            issues_str = \", \".join(issues)\n",
    "            if \"Incorrect or Missing Page Numbers\" in issues_str:\n",
    "                issues_str += f\" (pp: {extracted_pages})\"\n",
    "        else:\n",
    "            issues_str = \"None\"\n",
    "        detailed_issues.append(f\"Reference [{ref_index}] {year} Issues: {issues_str}\")\n",
    "    \n",
    "    return \"\\n\".join(formatted_references), detailed_issues\n",
    "\n",
    "def report_reference_fields(reference, ref_index):\n",
    "    \"\"\"\n",
    "    Extract and return a detailed report of the fields in a reference.\n",
    "    The report includes:\n",
    "      - Authors\n",
    "      - Title\n",
    "      - Journal name\n",
    "      - Volume\n",
    "      - Issue\n",
    "      - Page numbers\n",
    "      - Year\n",
    "      - DOI\n",
    "    \"\"\"\n",
    "    report = []\n",
    "    # Authors:\n",
    "    author_match = re.search(r\"^\\[\\d+\\]\\s*(.*?),\\s*“\", reference)\n",
    "    authors = author_match.group(1) if author_match else \"Missing\"\n",
    "    report.append(f\"Authors: {authors}\")\n",
    "    \n",
    "    # Title:\n",
    "    title_match = re.search(r\"“(.*?)”\", reference)\n",
    "    title = title_match.group(1) if title_match else \"Missing\"\n",
    "    report.append(f\"Title: {title}\")\n",
    "    \n",
    "    # Journal:\n",
    "    journal_match = re.search(r'“.*?”\\s*(.*?)\\s*,\\s*vol\\.', reference)\n",
    "    journal = journal_match.group(1) if journal_match else \"Missing\"\n",
    "    report.append(f\"Journal: {journal}\")\n",
    "    \n",
    "    # Volume:\n",
    "    vol_match = re.search(r\"vol\\.\\s*(\\d+)\", reference)\n",
    "    volume = vol_match.group(1) if vol_match else \"Missing\"\n",
    "    report.append(f\"Volume: {volume}\")\n",
    "    \n",
    "    # Issue:\n",
    "    issue_match = re.search(r\"no\\.\\s*(\\d+)\", reference)\n",
    "    issue = issue_match.group(1) if issue_match else \"Missing\"\n",
    "    report.append(f\"Issue: {issue}\")\n",
    "    \n",
    "    # Page Numbers:\n",
    "    pages_match = re.search(r\"pp\\.\\s*([\\d–]+)\", reference)\n",
    "    pages = pages_match.group(1) if pages_match else \"Missing\"\n",
    "    report.append(f\"Page numbers: {pages}\")\n",
    "    \n",
    "    # Year:\n",
    "    year = extract_year(reference)\n",
    "    report.append(f\"Year: {year}\")\n",
    "    \n",
    "    # DOI:\n",
    "    doi_match = re.search(r\"doi:\\s*(\\S+)\", reference)\n",
    "    doi = doi_match.group(1) if doi_match else \"Missing\"\n",
    "    report.append(f\"DOI: {doi}\")\n",
    "    \n",
    "    return \"\\n\".join(report)\n",
    "\n",
    "# --- Execution (not wrapped in a main function) ---\n",
    "\n",
    "input_references = \"\"\"[1]\tR. L. Siegel, K. D. Miller, N. S. Wagle, and A. Jemal, “Cancer statistics, 2023,” CA. Cancer J. Clin., vol. 73, no. 1, pp. 17–48, Jan. 2023, doi: 10.3322/caac.21763.\n",
    "[2]\tK. V. Sriram and R. H. Havaldar, “Analytical review and study on object detection techniques in the image,” Int. J. Model. Simul. Sci. Comput., vol. 12, no. 05, p. 2150031, Oct. 2021, doi: 10.1142/S1793962321500318.\n",
    "[3]\tL. Fan, H. Zhao, H. Zhao, H. Hu, and Z. Wang, “Survey of target detection based on deep convolutional neural networks,” Opt. Precis. Eng., vol. 28, no. 5, pp. 1152–1164, 2020, doi: 10.3788/ope.20202805.1152.\n",
    "[4]\tP. Viola and M. Jones, “Robust real-time face detection,” in Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001, Vancouver, BC, Canada: IEEE Comput. Soc, 2001, pp. 747–747, doi: 10.1109/ICCV.2001.937709.\n",
    "[5]\tN. Dalal and B. Triggs, “Histograms of Oriented Gradients for Human Detection,” in 2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR’05), San Diego, CA, USA: IEEE, 2005, pp. 886–893, doi: 10.1109/CVPR.2005.177.\n",
    "[6]\tM. Hussain, “YOLO-v1 to YOLO-v8, the Rise of YOLO and Its Complementary Nature toward Digital Manufacturing and Industrial Defect Detection,” Machines, vol. 11, no. 7, p. 677, Jun. 2023, doi: 10.3390/machines11070677.\n",
    "[7]\tG. Sharma, R. Dave, J. Sanadya, P. Sharma, and K. K. Sharma, “Various types and management of breast cancer: An overview,” J. Adv. Pharm. Technol. Res., vol. 1, no. 2, p. 109, 2010, doi: 10.4103/2231-4040.72251.\n",
    "[8]\tC. Li et al., “YOLOv6: A Single-Stage Object Detection Framework for Industrial Applications,” Sep. 07, 2022, arXiv: arXiv:2209.02976, doi: 10.48550/arXiv.2209.02976.\n",
    "[9]\tS. Zahia, D. Sierra-Sosa, B. Garcia-Zapirain, and A. Elmaghraby, “Tissue classification and segmentation of pressure injuries using convolutional neural networks,” Comput. Methods Programs Biomed., vol. 159, pp. 51–58, Jun. 2018, doi: 10.1016/j.cmpb.2018.02.018.\n",
    "[10]\tX. Sun, X. Wang, J. Liu, and H. Huang, “Classic YOLO Series Target Detection Algorithms and Their Application in Breast Cancer Detection,” J. Comput. Syst. Appl., vol. 32, no. 12, pp. 52–62, 2023, doi: 10.15888/j.cnki.csa.009351.\n",
    "[11]\tF. Prinzi, M. Insalaco, A. Orlando, S. Gaglio, and S. Vitabile, “A Yolo-Based Model for Breast Cancer Detection in Mammograms,” Cogn. Comput., vol. 16, no. 1, pp. 107–120, Jan. 2024, doi: 10.1007/s12559-023-10189-6.\n",
    "[12]\tP. K. Samanta, A. Basuli, N. K. Rout, and G. Panda, “Improved Breast Cancer Detection from Ultrasound Images Using YOLOv8 Model,” in 2023 IEEE 3rd International Conference on Applied Electromagnetics, Signal Processing, & Communication (AESPC), Bhubaneswar, India: IEEE, Nov. 2023, pp. 1–6, doi: 10.1109/AESPC59761.2023.10390341.\n",
    "[13]\tH. Gui et al., “FS-YOLOv9: A Frequency and Spatial Feature-Based YOLOv9 for Real-time Breast Cancer Detection,” Acad. Radiol., Oct. 2024, doi: 10.1016/j.acra.2024.09.048.\n",
    "[14]\tL. Zheng et al., “Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena,” Dec. 24, 2023, arXiv: arXiv:2306.05685, doi: 10.48550/arXiv.2306.05685.\n",
    "[15]\tA. Y. Yuan et al., “Hybrid deep learning network for vascular segmentation in photoacoustic imaging,” Biomed. Opt. Express, vol. 11, no. 11, p. 6445, Nov. 2020, doi: 10.1364/BOE.409246.\n",
    "[16]\tW. Al-Dhabyani, M. Gomaa, H. Khaled, and A. Fahmy, “Dataset of breast ultrasound images,” Data Brief, vol. 28, p. 104863, Feb. 2020, doi: 10.1016/j.dib.2019.104863.\n",
    "\"\"\"\n",
    "    \n",
    "# Process the references and get both the formatted references and detailed issues report.\n",
    "formatted_output, detailed_issues = process_references(input_references, start_index=1)\n",
    "\n",
    "print(\"Formatted References:\\n\", formatted_output)\n",
    "\n",
    "print(\"\\nFormat Issues Detected:\")\n",
    "for issue in detailed_issues:\n",
    "    print(issue)\n",
    "\n",
    "print(\"\\nDetailed Report per Reference:\")\n",
    "original_refs = re.split(r'\\n(?=\\[\\d+\\])', input_references.strip())\n",
    "for i, ref in enumerate(original_refs, start=1):\n",
    "    print(f\"\\nReference [{i}] Fields:\")\n",
    "    print(report_reference_fields(ref, i))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
