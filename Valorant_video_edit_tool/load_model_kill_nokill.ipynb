{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0815b8e-06c7-433e-9b22-9d2ea24f2c0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import torch\n",
    "import shutil\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Load the trained model\n",
    "def load_model(model_path, device):\n",
    "    model = models.resnet18(pretrained=False)\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = torch.nn.Linear(num_ftrs, 2)  # Assuming 2 classes: kill and no_kill\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model = model.to(device)\n",
    "    model.eval()  # Set to evaluation mode\n",
    "    return model\n",
    "\n",
    "# Preprocess a frame for the model (resize, normalize, etc.)\n",
    "def preprocess_frame(frame):\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    frame_tensor = preprocess(frame).unsqueeze(0)  # Add batch dimension\n",
    "    return frame_tensor\n",
    "\n",
    "# Function to classify a video based on the kill banner detection in frames\n",
    "def classify_video(model, device, video_path, frame_interval=30):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_count = 0\n",
    "    kill_detected = False\n",
    "\n",
    "    while True:\n",
    "        success, frame = cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "        \n",
    "        frame_count += 1\n",
    "        if frame_count % frame_interval == 0:  # Only process every nth frame\n",
    "            # Preprocess the frame\n",
    "            frame_tensor = preprocess_frame(frame).to(device)\n",
    "            \n",
    "            # Run the frame through the model\n",
    "            with torch.no_grad():\n",
    "                outputs = model(frame_tensor)\n",
    "                _, pred = torch.max(outputs, 1)\n",
    "            \n",
    "            # If a kill is detected in any frame, classify the video as 'kill'\n",
    "            if pred.item() == 0:  # Assuming '0' is the kill class\n",
    "                kill_detected = True\n",
    "                break  # Stop processing further frames as kill is detected\n",
    "\n",
    "    cap.release()  # Release the video capture\n",
    "    return kill_detected\n",
    "\n",
    "# Function to process all video clips in a folder and classify them\n",
    "def process_video_clips(input_folder, output_kill_folder, output_no_kill_folder, model, device):\n",
    "    # Ensure the output folders exist\n",
    "    if not os.path.exists(output_kill_folder):\n",
    "        os.makedirs(output_kill_folder)\n",
    "    if not os.path.exists(output_no_kill_folder):\n",
    "        os.makedirs(output_no_kill_folder)\n",
    "\n",
    "    # Use os.walk to traverse through all video files in the folder\n",
    "    for root, dirs, files in os.walk(input_folder):\n",
    "        for video_file in files:\n",
    "            if video_file.endswith(('.mp4', '.avi', '.mkv', '.mov')):  # Add other formats as needed\n",
    "                video_path = os.path.join(root, video_file)\n",
    "                print(f\"Processing video: {video_file}\")\n",
    "\n",
    "                # Classify the video based on the presence of a kill banner\n",
    "                kill_detected = classify_video(model, device, video_path)\n",
    "\n",
    "                # Determine the destination folder based on classification\n",
    "                if kill_detected:\n",
    "                    destination_folder = output_kill_folder\n",
    "                    print(f\"Copying {video_file} to 'kill' folder.\")\n",
    "                else:\n",
    "                    destination_folder = output_no_kill_folder\n",
    "                    print(f\"Copying {video_file} to 'no_kill' folder.\")\n",
    "                \n",
    "                # Ensure no overwriting by generating a unique filename\n",
    "                unique_name = get_unique_filename(destination_folder, video_file)\n",
    "                destination_path = os.path.join(destination_folder, unique_name)\n",
    "\n",
    "                # Copy the video to the determined destination folder\n",
    "                shutil.copy2(video_path, destination_path)\n",
    "\n",
    "# Helper function to generate unique filenames\n",
    "def get_unique_filename(destination_folder, filename):\n",
    "    base_name, extension = os.path.splitext(filename)\n",
    "    counter = 1\n",
    "    unique_name = filename\n",
    "    # Append a counter to the filename if the file already exists\n",
    "    while os.path.exists(os.path.join(destination_folder, unique_name)):\n",
    "        unique_name = f\"{base_name}_{counter}{extension}\"\n",
    "        counter += 1\n",
    "    return unique_name\n",
    "\n",
    "\n",
    "# Example usage\n",
    "input_folder = r'path to\\POV\\POV user'  # Folder containing video clips\n",
    "output_kill_folder = r'path to\\kill'  # Folder for classified 'kill' videos\n",
    "output_no_kill_folder = r'path to\\no_kill'  # Folder for classified 'no_kill' videos\n",
    "model_path = 'kill_banner_model.pth'  # Path to the trained model\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model(model_path, device)\n",
    "\n",
    "# Process all video clips and classify them\n",
    "process_video_clips(input_folder, output_kill_folder, output_no_kill_folder, model, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c735d93c-1724-4553-8837-72bfcc52196a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get kill frame\n",
    "# Function to classify a video based on the kill banner detection in frames and extract the first kill frame\n",
    "def classify_and_extract_kill_frame(model, device, video_path, frame_interval=60, output_frame_folder='kill_frames'):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_count = 0\n",
    "    kill_frame_extracted = False\n",
    "\n",
    "    # Ensure the output folder exists\n",
    "    if not os.path.exists(output_frame_folder):\n",
    "        os.makedirs(output_frame_folder)\n",
    "\n",
    "    while True:\n",
    "        success, frame = cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "\n",
    "        frame_count += 1\n",
    "        if frame_count % frame_interval == 0:  # Only process every nth frame (e.g., every second for 60 FPS)\n",
    "            # Preprocess the frame\n",
    "            frame_tensor = preprocess_frame(frame).to(device)\n",
    "\n",
    "            # Run the frame through the model\n",
    "            with torch.no_grad():\n",
    "                outputs = model(frame_tensor)\n",
    "                _, pred = torch.max(outputs, 1)\n",
    "\n",
    "            # If a kill is detected, save the frame and stop further processing\n",
    "            if pred.item() == 0:  # Assuming '0' is the kill class\n",
    "                kill_frame_extracted = True\n",
    "                # Save the frame as an image\n",
    "                frame_filename = os.path.join(output_frame_folder, f\"{os.path.basename(video_path)}_frame_{frame_count}.jpg\")\n",
    "                cv2.imwrite(frame_filename, frame)\n",
    "                print(f\"Kill frame extracted and saved at: {frame_filename}\")\n",
    "                break  # Stop processing once the first kill frame is found\n",
    "\n",
    "    cap.release()  # Release the video capture\n",
    "    return kill_frame_extracted\n",
    "\n",
    "# Function to process all video clips in a folder and extract kill frames\n",
    "def process_video_clips(input_folder, output_frame_folder, model, device, frame_interval=60):\n",
    "    # Traverse through all video files in the folder\n",
    "    for root, dirs, files in os.walk(input_folder):\n",
    "        for video_file in files:\n",
    "            if video_file.endswith(('.mp4', '.avi', '.mkv', '.mov')):  # Add other formats as needed\n",
    "                video_path = os.path.join(root, video_file)\n",
    "                print(f\"Processing video: {video_file}\")\n",
    "\n",
    "                # Classify the video and extract the first kill frame\n",
    "                classify_and_extract_kill_frame(\n",
    "                    model, device, video_path, frame_interval=frame_interval, output_frame_folder=output_frame_folder\n",
    "                )\n",
    "\n",
    "# Example usage\n",
    "input_folder = r'path to\\POV\\POV user'  # Folder containing video clips\n",
    "output_frame_folder = r'path to\\kill_frames'  # Folder to save extracted kill frames\n",
    "model_path = 'kill_banner_model.pth'  # Path to the trained model\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model(model_path, device)\n",
    "\n",
    "# Process all video clips and extract kill frames, adjusting for 60 FPS video\n",
    "process_video_clips(input_folder, output_frame_folder, model, device, frame_interval=60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73ea6e0-a2a4-43b1-b1d8-4d14600e585d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
